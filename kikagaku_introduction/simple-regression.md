## 01. 単回帰分析

- 問題設定
  例) 家賃予測
  y : 出力変数（家賃）
  x : 入力変数（広さ・距離）
  → 単回帰分析は入力変数が一つ・複数使う場合は重回帰に分析を利用する

### 1. 学習

x → モデル → y

モデルに規則を学習させる

### 2. 推論

x → 学習済みモデル → y

過去のデータから学習済みモデルを作成する
出力の値は **予測値** になる

## 02. モデルを決める

家賃を求める時に、次のモデルで考える

y^ = ax + b

- ^: ハット → 予測値を扱う時に利用する
- a, b: パラメータ

#### ゴール

データ(x1, x2, ..., y1, y2, ...) データに基づいて
「適切」にパラメータ a, b を決定する

- データの中心化(centering)
  - センタリングすると、 ax + b → ax にすることができる
  - データの中心は平均で出すことができる

[前提]
※データの中心化済み
y^ = ax

## 03. 評価関数を決める

「適切」を決める →「評価関数（損失関数）」を決める

y(実際値), y^(予測値)

50000, 65000 = 離れている量が良いか悪いかの判断になる
(50000 - 65000) ^2 で表現できる
|50000 - 65000| 絶対値でも良いのでは？<br/>
→ 微分は滑らかでないと計算できない<br/>
→ 2 乗でないと微分できない

二乗誤差と呼ぶ

$$
\bm{L} = (y_1 - \hat{y_1}) ^ 2 +
(y_2 - \hat{y_2}) ^ 2 + \cdots + 
(y_N - \hat{y_N}) ^ 2 \\
= \sum_{n=1}^N (y_n - \hat{y_n}) ^ 2
$$

## 04. 評価関数を最小にする

$$
\hat{y} = ax
$$

パラメーターaに対して、誤差の傾きが0になるようなものを求める

「傾き = 0」

$$
\frac{\partial}{\partial a} \bm{L} = 0 \\
L = \sum_{n=1}^N (y_n - \hat{y_n}) ^ 2 \tag{1}
$$

### step1. 式変形を行う

$$
\hat{y_n} = ax_n \tag{2}
$$

(1) に (2) を代入

$$
\bm{L} = \sum_{n=1}^N (y_n - ax_n) ^ 2 \\
= \sum_{n=1}^N y_n^2 - 2y_n ax_n + a^2 x_n^2 \\
= \sum_{n=1}^N y_n^2 - 2a (\sum_{n=1}^N y_n x_n) + a^2 (\sum_{n=1}^N x_n^2) \\
= C_0 - 2C_1 a+ C_2 a^2
$$

合計の部分を定数として扱う

### step2. さい駅なパラメータaを求める

step1より

$$
\frac{\partial}{\partial a} \bm{L} = 0 \\
L = C_0 - 2C_1 a+ C_2 a^2
$$

求めたい式

$$
\frac{\partial}{\partial a} (C_0 - 2C_1 a+ C_2 a^2) = 0 \\

\frac{\partial}{\partial a} (C_0) -
\frac{\partial}{\partial a} (2C_1 a) +
\frac{\partial}{\partial a} (C_2 a^2)
= 0 \\

2C_1 + 2 C_2 a
= 0 \\

2C_2 a  = 2C_1 \\

C_2 a = C_1 \\

a = \frac{C_1}{C_2}
= \frac{\sum_{n=1}^N y_n x_n}{\sum_{n=1}^N x_n^2}
$$